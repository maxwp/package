PHP 8.2 crazy performance benchmarks
@todo php 8.2 vs 8.3 vs 8.4

@author Maxim Miroshnichenko <max@miroshnichenko.org>

==============================================================

PHP 8.2.28 (cli) (built: Mar 13 2025 18:21:38) (NTS)
Copyright (c) The PHP Group
Zend Engine v4.2.28, Copyright (c) Zend Technologies with Zend OPcache v8.2.28, Copyright (c), by Zend Technologies

AWS EC2 c6gn.xlarge // c8g.xlarge
Важная ремарка: в процессе тестов я менял сервер, но это всегда оставался ARM Gravition*.
Важно смотреть не на абсолютное значение в ms (тем более оно на 1М итераций), а на соотношение одного способа к другому:
так можно понять как писать надо/ненадо ради ультра-производительности.

PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm

==============================================================

Ключевое:
- локальные переменные быстрее свойств (0 ms vs 7 ms),
  свойства быстрее свойсв-массивов (7 ms vs 17 ms)
- собаки @ это пиздец, +17 ms минимум, запускают debug backtrace если даже ошибок нет
- иногда выгоднее копирнуть свойство или элемент массива в локальную переменную и дальше с ней работать,
  потому что доступ к локальной переменной 0 ms, а доступ к свойству всегда 7, а свойству-массива 17 ms.
  Это только доступ, то есть получение указателя на кусочек памяти.
  Если писать $this->array['key'] то всегда ищется array, затем в нем всегда ищется key.
  И если такого кода дофига - пиздец производительности, просто тратим силы на поиск переменных.
- foreach сильно быстрее for
- closure & lamda это ад
- call trees не оптимизируются, никакого инлайнера внутри нет

==============================================================

Время в ms для 1_000_000 итераций:
- сам цикл заниает 4 ms и эти 4 ms я удалил из теста, дальше только чистые данные
- jit+opcache tracing 0.8 ms цикл
- дальше время всегда в формате без-jit-opcache / jit+opcache

==============================================================

Использование оператора подавления ошибок (@) резко замедляет код.
Дело в том, что PHP при этом всегда начинает собирать дополнительную информацию через debug backtrace, даже если ошибки нет.

Правда есть нюанс - isset лучше не добавлять, все-таки собакен:
if (isset($data['result']) && $data['result'] == 'pong') {} // 15.8 ms
if ($data['result'] == 'pong') {} // 9.8 ms
if (@$data['result'] == 'pong') {} // 12.8 ms

==============================================================

// получение указателя (доступ к пременной)
$a; // 0 ms локальная переменная
@$a; // 17 ms если учесть что переменная на самом деле инициирована; собака добавляет +17 ms на ровно месте
@$a; // 230 ms если переменная не инициирована, вот так собаки портят жизнь
$this->_a; // 7 ms / 5.42
@$this->_a; // 12 ms / 10.4

$this->_a['key3']; // 17 ms / 7.74
$this->_a['key1']['key2']; // 29 ms
$this->_a['key4']['key5']['key6']; // 41 ms
$this->_a;$this->_a;$this->_a; // 37 ms _a это массив
@$this->_a;@$this->_a;@$this->_a; // 45 ms _a это массив
$this->_b;$this->_b;$this->_b; // 20 ms _b это int/float/bool/string
@$this->_b;@$this->_b;@$this->_b; // 35 ms _b это int/float/bool/string

// это только поиск элемента по ключу, элемент существует
$this->_a['key1'];$this->_a['key2']; // 36 ms
$this->_a[1];$this->_a[2]; // 32 ms, числовые ключи чуть быстрее
$this->_b1;$this->_b2; // 13-14 ms (сходится с доступом к одному свойству)

// присвоение, $j динамически меняется
$this->_a['key'] = $j; // 19 ms
$this->_a = $j; // 7 ms / 4.3 ms
$a = $j; // 4 ms / 0.1 ms << супер ускорение

// переприсванивание из свойства в локальльную переменную (дальше к ней доступ 0 ms будет)
$a = $this->_b1; // 8-9 ms, фактически сохранить себе указатель сильно дешевле // 4.6 ms

$this->_a = $a; // 5 ms, если массив инициирован заранее $a = [1,2,3]; - сильно дешевле вдуть его сразу
$this->_a[1] = $a[1];$this->_a[2] = $a[2];$this->_a[3] = $a[3]; // 68 ms пиздец долго, сплошные malloc

$this->_a = 1; // 6 ms // 4.4 ms
$this->_a = 1; $this->_a *= 1; // 19 ms // 5.2 ms

// статическое присвоение быстрее массивом
$this->_a['a'] = 1;$this->_a['b'] = 2;$this->_a['c'] = 3; // 61 ms // 26 ms
$this->_a = array( // 8 ms // 4.4 ms
    'a' => 1,
    'b' => 2,
    'c' => 3,
);

// но если массив надо собирать - жопа
$this->_a['a'] = $j;$this->_a['b'] = $j;$this->_a['c'] = $j; // 58 ms // 26 ms << оптимизируется
$this->_a = array( // 67 ms // 67 ms, не оптимизируется, странно
    'a' => $j,
    'b' => $j,
    'c' => $j,
);
// поэтому лучше ебнуть в свойства
$this->_a = $j;$this->_b = $j;$this->_с = $j; // 28 ms // 23 ms, но важно чтобы свойства были
// еще лучше конечно в локальны переменные
$a = $j; $b = $j; $c = $j; // 12 ms // 1 ms << локальные перемеррые вообще жесть

// собирать статический массив лучше целиком сразу
$a = []; $a['key1'] = 1; $a['key2'] = 2; // 56 ms
$a = array( // 5 ms
    'key1' => 1,
    'key2' => 2,
);

// собирать массив выгоднее всего сразу и с числовыми ключами
$a = []; $a['key1'] = $j; $a['key2'] = $j; // 58 ms // 37 ms
$a = array( // 50 ms / 50 ms не оптимизируется jit-ом
    'key1' => $j,
    'key2' => $j,
);
$a = [$j, $j]; // 41 ms // 40 ms << не оптимизируется
= return [a, b] лучше не делать, лучше уже записать this->a, $this->b а потом их прочитать
= потому что собрать массив 50 ms, а сохранить в свойства 7+7=14 ms
= затем читать элементы из массива это 17+17=34 ms, а из свойств 7+7 = 14 ms
= итого разница 50+34=84 vs 14+14=28, то есть x3 раза
= при включенном jit 17-18 ms

Я провел еще один тест:
создавать assoc-массив [int, string], чтобы передать его return-ом и дальше по нему делать foreach = 485 ms / jit 358 ms
но если не создавать его, а сразу для каждого элемента дергать метод и передавать значения в виде аргументов = 262 ms / jit 170 ms
это еще раз доказывает что делать return [array] - пиздец как плохо, никакой jit не поможет

// если массив $tmp инициирован заранее (динамический) $tmp = [$t, $t, $t]; то выгоднее его сразу присвоить
// чем переписывать по-элементно
// (скорее всего там срабатывает cow)
// поэтому если что-то вернуло массив - то лучше его сразу и сохранять
$this->_a = $tmp; // 8 ms
$this->_a[0] = $tmp[0]; // 76 ms
$this->_a[1] = $tmp[1];
$this->_a[2] = $tmp[2];

==============================================================

// по массивам очень странный результат: без jit лучше формировать сразу, а с jit по очереди
// 128 ms // 111 ms jit
return array(
    'type' => $x,
    'ts_push' => $x,
    'datastream' => $x,
    'pair' => $x,
    'ts' => $x,
    'te' => $x,
    'sequence' => $x,
    'ask' => $x,
    'ask_size' => $x,
    'ask_breakout' => $x,
    'bid' => $x,
    'bid_size' => $x,
    'bid_breakout' => $x,
);

// 183 ms / 100 ms
$a = [];
$a['type'] = $x;
$a['ts_push'] = $x;
$a['datastream'] = $x;
$a['pair'] = $x;
$a['ts'] = $x;
$a['te'] = $x;
$a['sequence'] = $x;
$a['ask'] = $x;
$a['ask_size'] = $x;
$a['ask_breakout'] = $x;
$a['bid'] = $x;
$a['bid_size'] = $x;
$a['bid_breakout'] = $x;
return $a;

// 197 ms // 72 jit << самый медленный без jit, самый быстрый с jit
$a = $this->_template;
$a['type'] = $x;
$a['ts_push'] = $x;
$a['datastream'] = $x;
$a['pair'] = $x;
$a['ts'] = $x;
$a['te'] = $x;
$a['sequence'] = $x;
$a['ask'] = $x;
$a['ask_size'] = $x;
$a['ask_breakout'] = $x;
$a['bid'] = $x;
$a['bid_size'] = $x;
$a['bid_breakout'] = $x;
return $a;

где
    private array $_template = [
        'type' => null,
        'ts_push' => null,
        'datastream' => null,
        'pair' => null,
        'ts' => null,
        'te' => null,
        'sequence' => null,
        'ask' => null,
        'ask_size' => null,
        'ask_breakout' => null,
        'bid' => null,
        'bid_size' => null,
        'bid_breakout' => null,
    ];

// 157 ms // 130 ms jit
$a = new Data();
$a->type = $x;
$a->ts_push = $x;
$a->datastream = $x;
$a->pair = $x;
$a->ts = $x;
$a->te = $x;
$a->sequence = $x;
$a->ask = $x;
$a->ask_size = $x;
$a->ask_breakout = $x;
$a->bid = $x;
$a->bid_size = $x;
$a->bid_breakout = $x;
return $a;

// 210 ms // 180 ms << clone объектов это пиздец
$a = clone $this->_templateData;
$a->type = $x;
$a->ts_push = $x;
$a->datastream = $x;
$a->pair = $x;
$a->ts = $x;
$a->te = $x;
$a->sequence = $x;
$a->ask = $x;
$a->ask_size = $x;
$a->ask_breakout = $x;
$a->bid = $x;
$a->bid_size = $x;
$a->bid_breakout = $x;
return $a;

==============================================================

вытягивание ключей из массива:

когда пишем строчку типа $a['key1']['key2']['a'] - то ВСЕГДА происходит бинарный поиск по хеш-таблице массива.
И это не исправляет даже jit.
Ниже тесты без jit, с jit будет быстрее, но пропорция сохраняется.
Если что-то глубокое надо использовать больше одного раза - сильно выгоднее вытянуть это в локальную переменную.

// 70 ms
$a['key1']['key2']['a'];
$a['key1']['key2']['b'];
$a['key1']['key2']['c'];

// 40 ms
$x = $a['key1']['key2'];
$x['a'];
$x['b'];
$x['c'];

// 45 ms
$a['key1']['a'];
$a['key1']['b'];
$a['key1']['c'];

// 36 ms
$x = $a['key1'];
$x['a'];
$x['b'];
$x['c'];

// 31 ms
$a['key1']['a'];
$a['key1']['b'];

// 27 ms
$x = $a['key1'];
$x['a'];
$x['b'];

// кстати если 'a'/'b'/'c' надо будет юзать N раз - то выгоднее сохранить в локальную переменную его тоже

==============================================================

Втягивние переменных внутрь метода

1М вызовов метода:

// 16 ms call пустого метода
// 0 ms jit
private function _test() {}

// 22 ms если внутри метода один раз достать $this->_x;
// 12 ms jit
private function _test() {
    $this->_x;
}

// 89 ms если 10 раз достать $this->_x;
// 64 ms jit
private function _test() {
    $this->_x;
    ...
    $this->_x; // 10 раз
}

// 24 ms если переписаь в локальную переменную $x и дальше 10-20-30 раз ее дернуть
// 12 ms jit
private function _test() {
    $x = $this->_x;

    $x; $x; ... // сколько угодно раз
}

// 1151 ms для цикла с $this->_x
// но 2712 ms если $this->_x не была проиницирована, то есть просто private $_x; вместо private $_x = 1;
// надо быть супер аккуратным с инициацией
// 287 jit
private function _test() {
    for ($i = 0; $i < 100; $i++) {
        if ($this->_x > $i) {

        }
    }
}

// 784 ms для цикла с локальным $x
// это доказывает что лучше втягивать в локальную переменную
// но 2054 ms если $this->_x не была проиницирована, то есть просто private $_x; вместо private $_x = 1;
// надо быть супер аккуратным с инициацией
// 113 ms jit
private function _test() {
    $x = $this->_x;

    for ($i = 0; $i < 100; $i++) {
        if ($x > $i) {

        }
    }
}

// 1860 ms - какая-то жопа с указателями
private function _test() {
    $x = &$this->_x;

    for ($i = 0; $i < 100; $i++) {
        if ($x > $i) {

        }
    }
}

// 34 ms
// 18 ms jit
private function _test() {
    $this->_x['key1'];
}

// 2318 ms
// 740 ms jit
private function _test() {
    for ($i = 0; $i < 100; $i++) {
        if ($this->_x['key1'] > $i) {

        }
    }
}

// 800 ms, быстрее в 4 раза
// доступ по ключу массива это пиздец конечно
// 120 ms jit
private function _test() {
    $x = $this->_x['key1'];

    for ($i = 0; $i < 100; $i++) {
        if ($x > $i) {

        }
    }
}

==============================================================

call tree inlining

Кто-бы что-бы там не пиздел, php даже с jit не умеет инлайнить методы.
Пример:
Есть method1, который вызывает method2, который вызывает method3, и уже в method3 выполняется присваивание свойств.
Больше методы нигде не юзаются, все в одном классе, просто по очереди дерево вызовов 1>2>3.
В замерах я удалил время которое занимает сама логика присвоения, оставил только время цепочки call-вызовов.

Тест на 1М вызовов:
method 1 > 2 > 3 = 36 ms / 13.8 ms jit
method 2 > 3 = 23.5 ms / 10 ms jit
method 3 = 11 ms / 4 ms jit

jit ускоряет, но не решает проблему полностью.
Хочешь быстро - пиши простынями :)

==============================================================

foreach vs for:

foreach быстрее for, $a это 100 элементов int 1
foreach ($a as $x) {} // 930 ms // 540 ms
foreach ($a as $index => $x) {} // 1244 ms, то есть лишний index это пиздец // 543 ms jit
for ($x = 0; $x < count($a); $x++) {} // 1009 ms, и при этом еще нет доступа к элементу массива // 219 ms
for ($x = 0; $x < count($a); $x++) {$a[$x];} // 1888 ms, это уже с доступом // 643 ms
for ($x = 0; $x < 100; $x++) {$a[$x];} // 1352 ms // 636 ms
$cnt = count($a);for ($x = 0; $x < $cnt; $x++) {$a[$x];} // 1363 ms, то есть count в цикле это пиздец // 640 ms
$cnt = count($a);for ($x = 0; $x < $cnt; $x++) {} // 455 ms, быстрее foreach, но без доступа к элементу // 82 ms

==============================================================

printы:

1M вызовов print '.';
это 1749 ms > file.log
это 400 ms > /dev/null
А если выводить в консоль stdout - еще больший пиздец

==============================================================

new ClassName медленнее чем создание [array]

// 9 ms, но это статический массив
$x = array(
    'a' => 1,
    'b' => 1,
);

// 50 ms, это динамический массив, его нельзя инлайнить
$a = array(
    'key1' => $j,
    'key2' => $j,
);

new TmpClass($j, $j) // 84 ms

class TmpClass {
    public function __construct($a, $b) {
        $this->a = $a;
        $this->b = $b;
    }

    public $a, $b;
}

// new stdClass медленее чем мой класс TmpClass, хотя это пиздец,
// сама суть stdClass по документациям в том чтобы сделать ультра-быструю структуру
// и это статический stdClass
$x = new stdClass(); // 93 ms
$x->a = 1;
$x->b = 1;

==============================================================

call:

просто вызов любого метода $this->_method1() // 16 ms // 0 ms
если передать параметры $this->_method1($j) // 18 ms // 0 ms
каждый следующий параметр +2 ms
и это метод еще нихера не делает внутри, просто пустой

==============================================================

closure & lambda:

interface IReceiver {
    public function run($ts, $j);
}
class Receiver implements IReceiver {
    public function run($ts, $j) {}
}

    private function _run1($ts, callable $f) {
        for ($j = 1; $j <= 1_000_000; $j++) {
            $f($ts, $j);
        }
    }

    private function _run2($ts, IReceiver $receiver) {
        for ($j = 1; $j <= 1_000_000; $j++) {
            $receiver->run($ts, $j);
        }
    }

    private function _run3($ts) {
        for ($j = 1; $j <= 1_000_000; $j++) {
            $this->_receiver->run($ts, $j);
        }
    }

    private function _run4($ts) {
        $receiver = $this->_receiver;
        for ($j = 1; $j <= 1_000_000; $j++) {
            $receiver->run($ts, $j);
        }
    }

    // ниже числа где 1 раз вызывается _runX
    // closure тяжело передается, а use +1 параметр добавляет +6 ms на один вызов, не на 1М вызовов
    $this->_run1($t, function($ts, $j) {}); // 38 ms - for 4 ms = 34 ms
    $this->_run1($t, function($ts, $j) use ($t) {}); // 44 ms - 4 = 40 ms
    $this->_run1($t, $fn); // 38 ms -4 = 34 ms
    $this->_run2($t, $receiver); // 31 - 4 = 27 ms << самый быстрый способ это передать receiver 1 раз, он станет локальным в методе
    $this->_run3($t); // 36 ms - 4 = 32 ms (дерганье объекта хуевое)
    $this->_run4($t); // 31 ms - 4 = 27 ms << тоже самый лучший варант

Другой тест: если 1М раз вызывать run, каждый раз передавая callback в виде function или receiver
    $this->_run(array($this, '_callback1')); // 280 ms
    $this->_run(function ($ts, $x) {}); // 214 ms, чуть быстрее
    $this->_run($receiver); // 125 ms объект с invoke
    $this->_run($receiver); // 111 ms без invoke, разница в 2.5 раз

Итого: closure как-то херово инлайнится внутрь, лучше от него избавляться.
А lamda-use вообще шляпа.
Правда вот современные либы типа Rachet/react все на этой блямбда-хуйне.

==============================================================

strings concatenations:

самые большие проблемы это автоприведение типов, на втором месте конкатенация.

$s = $int.$int.$int; // 139 ms // 4.54 ms jit
$s = "$int$int$int"; // 117 ms << лучше всего сразу в одну строку // 4.5 ms
$s = $int; $int .= $int; $s .= $int; // 143 ms, клеить заметно хуже // 4.5 ms

// если $a и $b string - то значения не имеет как склеивать
$s = $a.$b; // 27 ms
$s = "$a$b"; // 28 ms
$s = $a; $s .= $b; // 40 ms, клеить по очереди всегда пиздец

// но для длинных строк - все равно выгодно клеить в одну строку
$s = $a.$b.$a.$b.$a.$b.$a.$b.$a.$b.$a.$b; // 192..194 ms
$s = "$a$b$a$b$a$b$a$b$a$b$a$b"; // 139..140 ms << самый выгодный вариант
$s = "{$a}{$b}{$a}{$b}{$a}{$b}{$a}{$b}{$a}{$b}{$a}{$b}"; // 139..140 ms, нифига не меняется
$s = $a; $s .= $b, ... и так дофига раз // 700+ ms, пиздец вам всем, так делать не надо

Это все обясняется бесконечным memory alloc и перекладываем переменных из памяти в память в новую бОльшую ячейку.
При jit это все исправили.

==============================================================

typing

Типизация конкатенацией - лажа, лучше явно string перед ним.
$j.''; // 24.5 ms (это без jit)
(string) $j; // 19.5 (это без jit)
strval($j); // 19.5

==============================================================

поиск подстроки в строке:

if (substr_count($s1, $s2)) { $x++; } // 14.28 ms // 9.35 jit
if (str_contains($s1, $s2)) { $x++; } // 12.38 ms // 9.15 ms jit << без jit самое быстрое
if (strpos($s1, $s2) !== false) { $x++; } // 14.68 ms // 8.47 jit << с jit лучше испорльзовать strpos

==============================================================

ifы:
и это йибать странно, у меня нет объяснений

// быстрее прыгнуть в if чем за него, это заставляет писать if (true) {} else { logic here } если нужно false
if (true) {} // 1.28 ms
if (false) {} // 2.84 ms

// для int проблем нет, хотя они и медленее :)
if (1) {} // 4.45 ms
if (0) {} // 4.73 ms

Upd: Неожиданное поведение связано с предсказанием переходов процессора и внутренней реализацией PHP: пустой true быстрее пустого false.
Если много пустых условий (встречается редко), убедись, что горячие пути чаще истинны (branch prediction friendly).

==============================================================

if vs switch:

так как скорость у switch & if-else одинаковая при jit, скорее всего jit умеет превращать if-else в switch.
Но, он явно не умеет косить пустые и бессмысленные if-else и пустые switch.

// 10 ms
// 0.5 ms jit
if ($opcode === 0x8) {

} elseif ($opcode === 0xA) {

} elseif ($opcode === 0x9) {

} else {

}

// 6.3 ms
// 0.5 ms jit
switch ($opcode) {
    case 0x8:
        break;
    case 0xA:
        break;
    case 0x9:
        break;
    default:
        break;
}

// супер важно чтобы тип данных в $x и case совпадал.
// если совпадает - 17 ms, если не совпадает - 60 ms (это все без jit).
// лучше всего сделать switch ((int)$x) - так будет 45 ms. Иначе оно походу типизирует под каждый case. Нахуя, не понятно.
// см string typing
switch ($x) {
    case 1:
        break/return; // а вот разницы return или break - значения никакого.
    case 2:
        break/return;
}

==============================================================

consts:

if (defined('myconst')) {} // 3.9 ms если false, 1.27 ms если true. Что тоже пиздец как логично ж
if ($this->_boolVar) {} // 4.88 ms

==============================================================

fill массивов:

for ($j = 0; $j < 1_000_000; ++$j) {
    $this->_test();
}

// 1098 ms
// 110 ms << при jit  это самый быстрый способ, без jit - самый медленный
private function _test() {
    $x = rand(1, 100);
    $a = [];
    for ($i = 1; $i <= $x; $i++) {
        $a[$i] = $i;
    }
}

// 930 ms - без индекса быстрее на 10%
// 499 ms << лучше с индексом при jit
private function _test() {
    $x = rand(1, 100);
    $a = [];
    for ($i = 1; $i <= $x; $i++) {
        $a[] = $i;
    }
}

// 1010 ms, если массив уже заполнен и я его копирую - трохи быстрее
// 490 ms
private $_bucket = array_fill(0, 100, 0);
private function _test() {
    $x = rand(1, 100);
    $a = $this->_bucket;
    for ($i = 1; $i <= $x; $i++) {
        $a[$i] = $i;
    }
}

// 865 ms, тоже самое, только bucket по указателю
// это странно конечно, работает только с массивами, с обычными переменными делает сильно хуже
// надо быть аккуратным, по перетирарается сам $this->_bucket
private $_bucket = array_fill(0, 100, 0);
private function _test() {
    $x = rand(1, 100);
    $a = &$this->_bucket;
    for ($i = 1; $i <= $x; $i++) {
        $a[$i] = $i;
    }
}

// 1180 ms, то то есть вызов $this->xxx пиздец тяжелый
// 406 ms
// но если надо таки записать в свойство, то лучше так чем собирать массив у себя локально потом присваивать - 506 ms jit
private $_bucket = array_fill(0, 100, 0);
private function _test() {
    $x = rand(1, 100);
    for ($i = 1; $i <= $x; $i++) {
        $this->_bucket[$i] = $i;
    }
}

==============================================================

ini_set('zend.enable_gc', 0);

Убирает запуск garbage collector, все становится чуть сложнее, но циклы стабильне.

==============================================================

OPCACHE + JIT

NB! шо opcache+jit это жопа с eval, если есть eval smarty - всему пизда сразу же

Синтетический тест на вызовы методов и доступ к свойствам:
php -f 1.php // 791 ms
php -d opcache.enable=1 -d opcache.validate_timestamps=1 -d opcache.revalidate_freq=0 -d opcache.enable_cli=1 -f 1.php // 642 ms opcache only
php -d opcache.enable=1 -d opcache.validate_timestamps=1 -d opcache.revalidate_freq=0 -d opcache.enable_cli=1 -d opcache.jit_buffer_size=100M -d opcache.jit=function -f 1.php // 244 ms
php -d opcache.enable=1 -d opcache.validate_timestamps=1 -d opcache.revalidate_freq=0 -d opcache.enable_cli=1 -d opcache.jit_buffer_size=100M -d opcache.jit=tracing -f 1.php // 114 ms

aws gn vs g сетевухи
Если не использовать DPDK/Kernel-by-pass то нет никакой разницы между gn или g для реального подключения по ws/udp.
Но вот скорость обработки самого сетевого стека сильно зависит от cpu и тут c8g выигрывает с ебейшим отрывом у всего остального.
Тестировал на подключении к fstream к одному IP из кластера c7gn, c7g, c8g.

m5zn.xlarge (intel xeon 4.5Ghz tokyo-only)
php 472 ms
php +opcache 333 ms
php +opcache +jit 78ms
network
no-jit  0.017221922	0.016291	0.010026	0.039792
jit	    0.016803216	0.015686	0.009896	0.03596

c7a.xlarge (top of amd 3.7Ghz)
php 491 ms
php +opcache 402 ms
php +opcache +jit 59 ms << супер быстрая математика
network
no-jit  0.023317672327672	0.02271	0.00912	0.0398
jit     не тестил, потому что проигрывает

c8g.xlarge << top of all
php 608 ms
php +opcache 384 ms
php +opcache +jit 75-80 ms << математика быстрая, но сеть просто ебическая
network << самый быстрый, IGW тоже топ
no-jit 0.0088250438247012	0.0080535	0.005574	0.033326 << монстр по сети, в 2.5 раза быстрее c6gn, в 1.5 раза быстрее c7g*
jit    0.008585994011976	0.007398	0.005503	0.032228 << не особо меняет

c8g.metal-24xl (arm, 96 vcpu)
php 607 ms
php +opcache 384 ms
php +opcache +jit 76 ms (чуть быстрее из-за отсутсвия context switching)
network
no-jit  0.005952433	0.005753	0.004636	0.014024 << top of network and performance, еще в 1.5 быстрее чем c8g shared, количество ядер решают на сетевой стек
jit     0.005866824	0.005636	0.004512	0.015603

c7gn.xlarge, c7g.xlarge (arm,  2.6Ghz, L-1M)
php 655 ms
php +opcache 435 ms, stable
php +opcache +jit 88 ms
network c7gn.xlarge
no-jit 	0.011871339	0.010371	0.007511	0.037104
jit 	0.012685706	0.0107155	0.007691	0.269821 делает чуть хуже?
network c7g.xlarge
no-jit  0.011913541	0.0101565	0.007481	0.036936 не похоже что чем-то отличется от c7gn
jit     0.012632865	0.0106905	0.007413	0.285803 делает чуть хуже, но нет разницы с c7gn

c7gn.metal (arm,  64 vcpu, 2.6Ghz, L-1M) - bare metal, без context-switching'a
php 655 ms
php +opcache 435 ms
php +opcache +jit 88 ms << больше ядер никак не помогает php-процессу и это логично
network
no-jit 	0.008225013986014	0.007976	0.006318	0.020987 << а вот не bare-metal у меня нет context-switching и больше ядер, сеть стала быстрее на +37%
jit     0.0079046816367265	0.0077845	0.006264	0.020894

c6gn.xlarge (arm, 2.5 GHz)
php 789 ms
php +opcache 641 ms
php +opcache +jit 114 ms
php +compiled 8.2.28 - 790 ms (= сборка php -O3 native не помогает)
php +compiled +opcache - 638 ms
php +compiled +opcache + jit 114 ms
network 0.0227 ms/udp loopback << это нитро сетевуха ENA, без ENA express
no-jit  0.02284175386 avg	0.02055975 med	0.01138 min 	0.4851 max
jit     0.02276954401 avg	0.020537 med	0.011126 min	0.37818 max не стабильное, но медиана самая низкая

c6a.xlarge (amd, 2.65 Ghz)
php 528 ms
php +opcache 380..574 ms, странно делает хуже и прыгает
php +opcache +jit 65 ms, стабильно << best of
network 0.045 ms/udp loopback, сеть вдвое хуже чем arm/intel
no-jit	0.048085801198801 avg	0.051471 med	0.01847 min	0.183734 max
jit 	0.045852571428571 avg	0.046251 med	0.02055 min	0.095102 max

c6i.xlarge (intel, 3.5 Ghz, сильно больше L-кешей)
php 520 ms
php +opcache 396 ms
php +opcache +jit 90 ms
network 0.0233 ms/udp loopback
no-jit  0.025813836 avg	0.0254155 med	0.011826 min	0.052407 max
jit     0.023273431 avg	0.022677 med	0.010959 min	0.054387 max    самое стабильное, но на 2% хуже arm

a1.metal (old arm)
php 2090 ms
php +opcache +jit 183 ms (ускоренеи норм, но все равно лажа с c6*)
сеть 0.03 ms/udp loopback, хуже в 1.5 раза
