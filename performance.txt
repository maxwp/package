PHP 8.2 crazy performance benchmarks
@todo php 8.2 vs 8.3 vs 8.4

@author Maxim Miroshnichenko <max@miroshnichenko.org>

==============================================================

СУПЕР ВАЖНАЯ РЕМАРКА:
Тесты проводились в разное время и иногда на разных серверах.
Поэтому важно сравнивать не просто миллисекунды, а скорее соотношение "во сколько раз быстрее или медленне один подход от другого.

==============================================================

PHP 8.2.28 (cli) (built: Mar 13 2025 18:21:38) (NTS)
Copyright (c) The PHP Group
Zend Engine v4.2.28, Copyright (c) Zend Technologies with Zend OPcache v8.2.28, Copyright (c), by Zend Technologies

AWS EC2 c6gn.xlarge // c8g.xlarge
Важная ремарка: в процессе тестов я менял сервер, но это всегда оставался ARM Gravition*.
Важно смотреть не на абсолютное значение в ms (тем более оно на 1М итераций), а на соотношение одного способа к другому:
так можно понять как писать надо/ненадо ради ультра-производительности.

PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm

==============================================================

Ключевое:
- локальные переменные быстрее свойств (0 ms vs 7 ms),
  свойства быстрее свойсв-массивов (7 ms vs 17 ms)
- собаки @ это пиздец, +17 ms минимум, запускают debug backtrace если даже ошибок нет
- иногда выгоднее копирнуть свойство или элемент массива в локальную переменную и дальше с ней работать,
  потому что доступ к локальной переменной 0 ms, а доступ к свойству всегда 7, а свойству-массива 17 ms.
  Это только доступ, то есть получение указателя на кусочек памяти.
  Если писать $this->array['key'] то всегда ищется array, затем в нем всегда ищется key.
  И если такого кода дофига - пиздец производительности, просто тратим силы на поиск переменных.
- foreach сильно быстрее for
- closure & lamda это ад
- call trees не оптимизируются, никакого инлайнера внутри нет

==============================================================

Время в ms для 1_000_000 итераций:
- сам цикл заниает 4 ms и эти 4 ms я удалил из теста, дальше только чистые данные
- jit+opcache tracing 0.8 ms цикл
- дальше время всегда в формате без-jit-opcache / jit+opcache

==============================================================

Использование оператора подавления ошибок (@) резко замедляет код.
Дело в том, что PHP при этом всегда начинает собирать дополнительную информацию через debug backtrace, даже если ошибки нет.

Правда есть нюанс - isset лучше не добавлять, все-таки собакен:
if (isset($data['result']) && $data['result'] == 'pong') {} // 15.8 ms
if ($data['result'] == 'pong') {} // 9.8 ms
if (@$data['result'] == 'pong') {} // 12.8 ms

// 18 ms
if (($this->_seqArray[$key] ?? -1) >= $j) {
    continue;
}
$this->_seqArray[$key] = $j;

// 25 ms
if (isset($this->_seqArray[$key]) && $j <= $this->_seqArray[$key]) {
    continue;
}
$this->_seqArray[$key] = $j;

// 30 ms
$link = &$this->_seqArray[$key];
if (isset($link) && $j <= $link) {
    continue;
}
$link = $j;

// 14 ms - но с notice разово << это самый лучший вариант, но надо инициировать ключи заранее
if ($j <= $this->_seqArray[$key]) {
    continue;
}
$this->_seqArray[$key] = $j;

// 16 ms
if ($j <= @$this->_seqArray[$key]) {
    continue;
}
$this->_seqArray[$key] = $j;

// 20 ms
$prev = @$this->_seqArray[$key];
if ($j <= $prev) {
    continue;
}
$this->_seqArray[$key] = $j;

==============================================================

isset vs count

Если вам нужно проверить есть ли все нужные элементы в массиве - то сильно выгоднее использовать isset на нужный элемент.
Например:
$data = explode(';', $data);
вместо if (count($data) >= 10) лучше писать if (isset($data[9]))

Разница почти в 4 раза.

==============================================================

// получение указателя (доступ к пременной)
$a; // 0 ms локальная переменная
@$a; // 17 ms если учесть что переменная на самом деле инициирована; собака добавляет +17 ms на ровно месте
@$a; // 230 ms если переменная не инициирована, вот так собаки портят жизнь
$this->_a; // 7 ms / 5.42
@$this->_a; // 12 ms / 10.4

$a['key']; // 8 ms -- всегда поиск по ключу массива

$this->_a['key3']; // 17 ms / jit 7.74 ms -- тут сначала поиск свойства, затем поиск по ключу массива
$this->_a['key1']['key2']; // 29 ms
$this->_a['key4']['key5']['key6']; // 41 ms
$this->_a;$this->_a;$this->_a; // 37 ms _a это массив
@$this->_a;@$this->_a;@$this->_a; // 45 ms _a это массив
$this->_b;$this->_b;$this->_b; // 20 ms _b это int/float/bool/string
@$this->_b;@$this->_b;@$this->_b; // 35 ms _b это int/float/bool/string

// это только поиск элемента по ключу, элемент существует
$this->_a['key1'];$this->_a['key2']; // 36 ms
$this->_a[1];$this->_a[2]; // 32 ms, числовые ключи чуть быстрее
$this->_b1;$this->_b2; // 13-14 ms (сходится с доступом к одному свойству)

// присвоение, $j динамически меняется
$this->_a['key'] = $j; // 19 ms
$this->_a = $j; // 7 ms / 4.3 ms
$a = $j; // 4 ms / 0.1 ms << супер ускорение

// переприсванивание из свойства в локальльную переменную (дальше к ней доступ 0 ms будет)
$a = $this->_b1; // 8-9 ms, фактически сохранить себе указатель сильно дешевле // 4.6 ms

$this->_a = $a; // 5 ms, если массив инициирован заранее $a = [1,2,3]; - сильно дешевле вдуть его сразу
$this->_a[1] = $a[1];$this->_a[2] = $a[2];$this->_a[3] = $a[3]; // 68 ms пиздец долго, сплошные malloc

$this->_a = 1; // 6 ms // 4.4 ms
$this->_a = 1; $this->_a *= 1; // 19 ms // 5.2 ms

// статическое присвоение быстрее массивом
$this->_a['a'] = 1;$this->_a['b'] = 2;$this->_a['c'] = 3; // 61 ms // 26 ms
$this->_a = array( // 8 ms // 4.4 ms
    'a' => 1,
    'b' => 2,
    'c' => 3,
);

// но если массив надо собирать - жопа
$this->_a['a'] = $j;$this->_a['b'] = $j;$this->_a['c'] = $j; // 58 ms // 26 ms << оптимизируется
$this->_a = array( // 67 ms // 67 ms, не оптимизируется, странно
    'a' => $j,
    'b' => $j,
    'c' => $j,
);
// поэтому лучше ебнуть в свойства
$this->_a = $j;$this->_b = $j;$this->_с = $j; // 28 ms // 23 ms, но важно чтобы свойства были
// еще лучше конечно в локальны переменные
$a = $j; $b = $j; $c = $j; // 12 ms // 1 ms << локальные перемеррые вообще жесть

// собирать статический массив лучше целиком сразу
$a = []; $a['key1'] = 1; $a['key2'] = 2; // 56 ms
$a = array( // 5 ms
    'key1' => 1,
    'key2' => 2,
);

// собирать массив выгоднее всего сразу и с числовыми ключами
$a = []; $a['key1'] = $j; $a['key2'] = $j; // 58 ms // 37 ms
$a = array( // 50 ms / 50 ms не оптимизируется jit-ом
    'key1' => $j,
    'key2' => $j,
);
$a = [$j, $j]; // 41 ms // 40 ms << не оптимизируется
= return [a, b] лучше не делать, лучше уже записать this->a, $this->b а потом их прочитать
= потому что собрать массив 50 ms, а сохранить в свойства 7+7=14 ms
= затем читать элементы из массива это 17+17=34 ms, а из свойств 7+7 = 14 ms
= итого разница 50+34=84 vs 14+14=28, то есть x3 раза
= при включенном jit 17-18 ms

Я провел еще один тест:
создавать assoc-массив [int, string], чтобы передать его return-ом и дальше по нему делать foreach = 485 ms / jit 358 ms
но если не создавать его, а сразу для каждого элемента дергать метод и передавать значения в виде аргументов = 262 ms / jit 170 ms
это еще раз доказывает что делать return [array] - пиздец как плохо, никакой jit не поможет

// если массив $tmp инициирован заранее (динамический) $tmp = [$t, $t, $t]; то выгоднее его сразу присвоить
// чем переписывать по-элементно
// (скорее всего там срабатывает cow)
// поэтому если что-то вернуло массив - то лучше его сразу и сохранять
$this->_a = $tmp; // 8 ms
$this->_a[0] = $tmp[0]; // 76 ms
$this->_a[1] = $tmp[1];
$this->_a[2] = $tmp[2];

==============================================================

// по массивам очень странный результат: без jit лучше формировать сразу, а с jit по очереди
// см ниже DTO, оно лучше в 2-3 раза и работает с jit

// 128 ms // 111 ms jit
return array(
    'type' => $x,
    'ts_push' => $x,
    'datastream' => $x,
    'pair' => $x,
    'ts' => $x,
    'te' => $x,
    'sequence' => $x,
    'ask' => $x,
    'ask_size' => $x,
    'ask_breakout' => $x,
    'bid' => $x,
    'bid_size' => $x,
    'bid_breakout' => $x,
);

// 183 ms / 100 ms
$a = [];
$a['type'] = $x;
$a['ts_push'] = $x;
$a['datastream'] = $x;
$a['pair'] = $x;
$a['ts'] = $x;
$a['te'] = $x;
$a['sequence'] = $x;
$a['ask'] = $x;
$a['ask_size'] = $x;
$a['ask_breakout'] = $x;
$a['bid'] = $x;
$a['bid_size'] = $x;
$a['bid_breakout'] = $x;
return $a;

// 197 ms // 72 jit << самый медленный без jit, самый быстрый с jit
$a = $this->_template;
$a['type'] = $x;
$a['ts_push'] = $x;
$a['datastream'] = $x;
$a['pair'] = $x;
$a['ts'] = $x;
$a['te'] = $x;
$a['sequence'] = $x;
$a['ask'] = $x;
$a['ask_size'] = $x;
$a['ask_breakout'] = $x;
$a['bid'] = $x;
$a['bid_size'] = $x;
$a['bid_breakout'] = $x;
return $a;

где
    private array $_template = [
        'type' => null,
        'ts_push' => null,
        'datastream' => null,
        'pair' => null,
        'ts' => null,
        'te' => null,
        'sequence' => null,
        'ask' => null,
        'ask_size' => null,
        'ask_breakout' => null,
        'bid' => null,
        'bid_size' => null,
        'bid_breakout' => null,
    ];

// 157 ms // 130 ms jit
$a = new Data();
$a->type = $x;
$a->ts_push = $x;
$a->datastream = $x;
$a->pair = $x;
$a->ts = $x;
$a->te = $x;
$a->sequence = $x;
$a->ask = $x;
$a->ask_size = $x;
$a->ask_breakout = $x;
$a->bid = $x;
$a->bid_size = $x;
$a->bid_breakout = $x;
return $a;

// 210 ms // 180 ms << clone объектов это пиздец
$a = clone $this->_templateData;
$a->type = $x;
$a->ts_push = $x;
$a->datastream = $x;
$a->pair = $x;
$a->ts = $x;
$a->te = $x;
$a->sequence = $x;
$a->ask = $x;
$a->ask_size = $x;
$a->ask_breakout = $x;
$a->bid = $x;
$a->bid_size = $x;
$a->bid_breakout = $x;
return $a;

==============================================================

вытягивание ключей из массива:

когда пишем строчку типа $a['key1']['key2']['a'] - то ВСЕГДА происходит бинарный поиск по хеш-таблице массива.
И это не исправляет даже jit.
Ниже тесты без jit, с jit будет быстрее, но пропорция сохраняется.
Если что-то глубокое надо использовать больше одного раза - сильно выгоднее вытянуть это в локальную переменную.

// 70 ms
$a['key1']['key2']['a'];
$a['key1']['key2']['b'];
$a['key1']['key2']['c'];

// 40 ms
$x = $a['key1']['key2'];
$x['a'];
$x['b'];
$x['c'];

// 45 ms
$a['key1']['a'];
$a['key1']['b'];
$a['key1']['c'];

// 36 ms
$x = $a['key1'];
$x['a'];
$x['b'];
$x['c'];

// 31 ms
$a['key1']['a'];
$a['key1']['b'];

// 27 ms
$x = $a['key1'];
$x['a'];
$x['b'];

// кстати если 'a'/'b'/'c' надо будет юзать N раз - то выгоднее сохранить в локальную переменную его тоже

==============================================================

Вытягивание свойств (которые объекты в локальные переменные)
Да, разница есть даже для 2х вызовов.

// 19-20 ms
$this->_pairConfig->amountTick;
$this->_pairConfig->amountTick;

// 17-18 ms
$pc = $this->_pairConfig;
$pc->amountTick;
$pc->amountTick;

При 1м вызове - хуже.
При 2х - уже лучше (17 ms vs 19 ms)
При 3х - еще лучше (23 ms vs 30 ms)
И так далее.

То есть да, все что 2 раза вызывается - лучше вытягивать в locals.

==============================================================

Динамическая типизация в if-ах

if ($x) {} // если $x = null; то 5.5 ms
if ($x > 0) {} // если $x = null; то 8.7 ms
if ($x) {} // если $x = 1.0; то 3.7 ms
if ($x > 0) {} // если $x = 1.0; то 3.7 ms
if ($x) {} // если $x = 1; (int) - то 4 ms
if ($x > 0) {} // если $x = 1; (int) то 3.7 ms
if ($x) {} // $x = true; 3.5 ms
if (!$x) {} // $x = false; 4.0 ms
if ($x > 0) {} // $x = false; 8 ms

Итого:
= надо избегать типизаци в if-ах
= надо избегать null
= лучше всего для сравниений >0 <0 использовать float, int почему-то типизируется хуже
= быстре всего if true с bool внутри,

==============================================================

// Операции сравнения с int float - не имеют значения
// Но это потому что результат надо приврдить в bool
// Если отдельно надо отнять/перемножить/поделить - то int быстрее в 2 раза

// float:
if ($a != $b) {} // 3.96
if ($a - $b != 0) {} // 5.5
if ($a - $b > 0) {} // 6.5

// int:
if ($a != $b) {} // 3.9
if ($a - $b != 0) {} // 5.5
if ($a - $b > 0) {} // 6.5

==============================================================

$x ++ сильно быстрее $x += 1;

$x ++; // 0.5 ms
$x += 1; // 3.6 ms

Для $x-- тоже самое.
++$x и $x++ одинаково быстро тоже.

==============================================================

Счетчик сильно быстрее в int

// 0.5 ms
$x = 1;
for ($j = 0; $j < 1_000_000; $j++) {
    $x++;
}

// 5.5 ms
$x = 'a';
for ($j = 0; $j < 1_000_000; $j++) {
    $x++;
}

==============================================================

Параллельные массивы лучше вложенных,
это объясняется дорогим доступом к $message[i],
а также очень тяжелой клейкой array = [a, b, c]

// 197-198 ms
$messageArray = [];
$n = rand(1,3);
for ($loop = 1; $loop <= $n; $loop++) {
    $messageArray[] = [$t, $j, $loop];
}
foreach ($messageArray as $message) {
    $this->_call($message[0], $message[1], $message[2]);
}

// 179 ms
$a = [];
$b = [];
$c = [];
$n = rand(1,3);
for ($loop = 1; $loop <= $n; $loop++) {
    $a[] = $t;
    $b[] = $j;
    $c[] = $loop;
}
for ($i = 0; $i < $n; $i++) {
    $this->_call($a[$i], $b[$i], $c[$i]);
}

==============================================================

Втягивние переменных внутрь метода

1М вызовов метода:

// 16 ms call пустого метода
// 0 ms jit
private function _test() {}

// 22 ms если внутри метода один раз достать $this->_x;
// 12 ms jit
private function _test() {
    $this->_x;
}

// 89 ms если 10 раз достать $this->_x;
// 64 ms jit
private function _test() {
    $this->_x;
    ...
    $this->_x; // 10 раз
}

// 24 ms если переписаь в локальную переменную $x и дальше 10-20-30 раз ее дернуть
// 12 ms jit
private function _test() {
    $x = $this->_x;

    $x; $x; ... // сколько угодно раз
}

// 1151 ms для цикла с $this->_x
// но 2712 ms если $this->_x не была проиницирована, то есть просто private $_x; вместо private $_x = 1;
// надо быть супер аккуратным с инициацией
// 287 jit
private function _test() {
    for ($i = 0; $i < 100; $i++) {
        if ($this->_x > $i) {

        }
    }
}

// 784 ms для цикла с локальным $x
// это доказывает что лучше втягивать в локальную переменную
// но 2054 ms если $this->_x не была проиницирована, то есть просто private $_x; вместо private $_x = 1;
// надо быть супер аккуратным с инициацией
// 113 ms jit
private function _test() {
    $x = $this->_x;

    for ($i = 0; $i < 100; $i++) {
        if ($x > $i) {

        }
    }
}

// 1860 ms - какая-то жопа с указателями
private function _test() {
    $x = &$this->_x;

    for ($i = 0; $i < 100; $i++) {
        if ($x > $i) {

        }
    }
}

// 34 ms
// 18 ms jit
private function _test() {
    $this->_x['key1'];
}

// 2318 ms
// 740 ms jit
private function _test() {
    for ($i = 0; $i < 100; $i++) {
        if ($this->_x['key1'] > $i) {

        }
    }
}

// 800 ms, быстрее в 4 раза
// доступ по ключу массива это пиздец конечно
// 120 ms jit
private function _test() {
    $x = $this->_x['key1'];

    for ($i = 0; $i < 100; $i++) {
        if ($x > $i) {

        }
    }
}

==============================================================

call tree inlining

Кто-бы что-бы там не пиздел, php даже с jit не умеет инлайнить методы.
Пример:
Есть method1, который вызывает method2, который вызывает method3, и уже в method3 выполняется присваивание свойств.
Больше методы нигде не юзаются, все в одном классе, просто по очереди дерево вызовов 1>2>3.
В замерах я удалил время которое занимает сама логика присвоения, оставил только время цепочки call-вызовов.

Тест на 1М вызовов:
method 1 > 2 > 3 = 36 ms / 13.8 ms jit
method 2 > 3 = 23.5 ms / 10 ms jit
method 3 = 11 ms / 4 ms jit

jit ускоряет, но не решает проблему полностью.
Хочешь быстро - пиши простынями :)

==============================================================

foreach vs for:

foreach быстрее for, $a это 100 элементов int 1
foreach ($a as $x) {} // 930 ms // 540 ms
foreach ($a as $index => $x) {} // 1244 ms, то есть лишний index это пиздец // 543 ms jit
for ($x = 0; $x < count($a); $x++) {} // 1009 ms, и при этом еще нет доступа к элементу массива // 219 ms
for ($x = 0; $x < count($a); $x++) {$a[$x];} // 1888 ms, это уже с доступом // 643 ms
for ($x = 0; $x < 100; $x++) {$a[$x];} // 1352 ms // 636 ms
$cnt = count($a);for ($x = 0; $x < $cnt; $x++) {$a[$x];} // 1363 ms, то есть count в цикле это пиздец // 640 ms
$cnt = count($a);for ($x = 0; $x < $cnt; $x++) {} // 455 ms, быстрее foreach, но без доступа к элементу // 82 ms

==============================================================

if + foreach

Часто возникают ситуации, что если есть массив и по нему надо сделать foreach, но массив может быть пустой.
И что выгоднее - if ($array) { foreach($array ...)
или сразу $foreach даже если массив пустой?

Правильный ответ зависит от того, что в вашем случае вероятнее: пустой массив или нет?
Потому что if ($array) для пустого массива 2.3 ms (на 1М вызовов)
а если в массиве что-то есть, то if ($array) будет 0.7 ms (что сильно быстрее).
В тоже время foreach для массива с 1м элементом - 10 ms,
для пустого массива - 4.4 ms.

Если вероятность пустого массива 50% - то
foreach    = 0.5 x 4.4 + 0.5 x 10 = 7.2 ms
if+foreach = 0.5 x 2.3 + 0.5 x (0.7 + 10) = 6.5 ms << наличие if оправдано

Если вероятность пустого массива 10%:
foreach    = 0.1 x 4.4 + 0.9 x 10 = 9.44 ms
if+foreach = 0.1 x 2.3 + 0.9 x (0.7 + 10) = 9.86 ms << if НЕ оправдан

Если вероятность пустого массива 90%:
foreach    = 0.9 x 4.4 + 0.1 x 10 = 4.96 ms
if+foreach = 0.9 x 2.3 + 0.1 x (0.7 + 10) = 3.14 ms << наличие if оправдано

Важно: это тест с массивом на 1 элемент. Если элементов больше - надо пересчитывать EV.

==============================================================

foreach ($this->_a as $x) {} // 26 ms

foreach ($this->getArray() as $x) {} // 38 ms
где public function getArray() {
    return $this->_a;
}

но разница в 12 ms сохраняется сколько бы элементов в массиве не было.
То есть, разница только на одном call method + return указатель на массив.
Главное, конечно, массив не тереть внутри цикла.

Итого: делать readonly public array смысла мало, если это не hotpath а какой-нибудь симулятор с большим количеством данных - то можно смело прятать данные в getArray()

==============================================================

printы:

1M вызовов print '.';
это 1749 ms > file.log
это 400 ms > /dev/null
А если выводить в консоль stdout - еще больший пиздец

==============================================================

new ClassName медленнее чем создание [array]

// 9 ms, но это статический массив
$x = array(
    'a' => 1,
    'b' => 1,
);

// 50 ms, это динамический массив, его нельзя инлайнить
$a = array(
    'key1' => $j,
    'key2' => $j,
);

new TmpClass($j, $j) // 84 ms

class TmpClass {
    public function __construct($a, $b) {
        $this->a = $a;
        $this->b = $b;
    }

    public $a, $b;
}

// new stdClass медленее чем мой класс TmpClass, хотя это пиздец,
// сама суть stdClass по документациям в том чтобы сделать ультра-быструю структуру
// и это статический stdClass
$x = new stdClass(); // 93 ms
$x->a = 1;
$x->b = 1;

==============================================================

Вызов метода с множественными аргументами:

в php8 появилась возможность делать вот так:
public function ppp1(...$args) {}

так вот, вызов
// 44 ms
$this->ppp1(1,2,3);

// 38 ms
$this->ppp2(1);
$this->ppp2(2);
$this->ppp2(3);

походе что множественные аргументы передаются как хитро-выебанный массив, ну их нахуй,
call стоит дороже.

==============================================================

arrays vs DTO:
я конечно за все прекрасное ООП, но только вот DTO в 3 раза медленее чем array с ключами, особенно если есть jit.
jit ускоряет массивы, но никак не ускоряет DTO. Хоть самому инлайнер пиши.

// это долгий вариант, наличие конструктора и типизации свойств делает инициализацию объекта сильно долгим
class DTO {

    public function __construct($a, $b, $c) {
        $this->a = $a;
        $this->b = $b;
        $this->c = $c;
    }

    public readonly int $a;
    public readonly int $b;
    public readonly int $c;

}

$x = new DTO($j, $j, $j); // 86 ms
$x->a; // если читать ключи - то суммарно 99 ms // 92 jit не помогает
$x->b;
$x->c;

$x = array( // 40 ms
    'a' => $j,
    'b' => $j,
    'c' => $j,
);
$x['a']; // если читать ключи - то суммарно 61 ms // 42 jit помогает
$x['b'];
$x['c'];

$x = []; // 46 ms << это самый быстрый пособ при jit
$x['a'] = $j;
$x['b'] = $j;
$x['c'] = $j;
$x['a']; //  если читать ключи - то суммарн 69 ms /  34 ms jit
$x['b'];
$x['c'];

class DTO1 {

    public int $a = 1;
    public $b = 2;
    public readonly int $c;

    public function __construct() {
        $this->c = 3;
    }

}
$tmp->a;
$tmp->b;
$tmp->c;

итого: нет никакой разницы вообще, именно чтение свойств шо типизированные шо readonly не имеет значения.

// самый быстрый вариант: без типов данных и без констуктора
class DTO {

    public $a; // супер важно не писать тут типы данных
    public $b;
    public $c;

    // тут можно добавлять свои методы, на скорость не влияет
}

$x = $this->_dto1; // 21 ms / jit 8 ms << лучший вариант
$x->a = $j;
$x->b = $j;
$x->c = $j;

$x = $this->_dtoArray['binancefp-XMRUSDT']; // 29 ms / jit 12 ms << лучший вариант
$x->a = $j;
$x->b = $j;
$x->c = $j;

$x = new DTO(); // 42 ms / jit 24 ms
$x->a = $j;
$x->b = $j;
$x->c = $j;

$x = clone $this->_dto1; // 57 ms / jit 43 ms
$x->a = $j;
$x->b = $j;
$x->c = $j;

$a = array( // 40 ms / jit 37 ms
'a' => $j,
'b' => $j,
'c' => $j,
);

Итого:
1. DTO лучше массива если в нем нет типов данных (на свойствах) и если в нем нет конструктора
2. идеально иметь один объект DTO и все время в нем менять значения и выдавать его
3. clone использовать нельзя, просто очень долго
4. если нужно держать указатели на более чем 1 объект - то memory pool хорошее решение, даже с key-value массивом
5. чтение из DTO быстрее чем из массива, плюс IDE еще и подсказывает:
   чтение по ключу массива - 7-8 ms (без jit)
   чтение по свойству dto - 4-5 ms (без jit)
6. чем больше свойств в DTO - тем дольше инициализация new DTO(), но это все равно быстрее нового array.
7. в свойствах DTO нельзя добавлять типы данных
   и нельзя делать инициализацию public $c = 0.0;
   это приводит к заметному замедлению при new (именно при new)

==============================================================

call:

просто вызов любого метода $this->_method1() // 16 ms // 0 ms
если передать параметры $this->_method1($j) // 18 ms // 0 ms
каждый следующий параметр +2 ms
и это метод еще нихера не делает внутри, просто пустой

==============================================================

DTO vs new DTO vs isset

// 59 ms
$this->_x = new DTO();
$x = $this->_x;
$x->a = $j;
$x->b = $j;
$x->c = $j;

$x = new DTO(); // 56 ms
$x->a = $j;
$x->b = $j;
$x->c = $j;
$this->_x = $x;

// 28 ms
if (empty($this->_x)) { // если не известно DTO инициирован или нет
    $this->_x = new DTO();
}
$x = $this->_x;
$x->a = $j;
$x->b = $j;
$x->c = $j;

// 24 ms
if ($this->_xEmpty) { // еще быстрее, потому что нет типизации объекта к bool
    $this->_x = new DTO();
    $this->_xEmpty = false;
}
$x = $this->_x;
$x->a = $j;
$x->b = $j;
$x->c = $j;

// 25 ms
if (!$this->_xInited) { // сильно легче заходить в true условия
    $this->_x = new DTO();
    $this->_xInited = true;
}
$x = $this->_x;
$x->a = $j;
$x->b = $j;
$x->c = $j;

// 21 ms
$x = $this->_x; // _x это DTO и он уже проинициирован
$x->a = $a;
$x->b = $b;
$x->c = $c;

// 17 ms
$this->_call($a, $b, $c); // << идеально всегда заменять на call и не заниматься присвоением хуйни в DTO или Array


==============================================================

closure & lambda:

interface IReceiver {
    public function run($ts, $j);
}
class Receiver implements IReceiver {
    public function run($ts, $j) {}
}

    private function _run1($ts, callable $f) {
        for ($j = 1; $j <= 1_000_000; $j++) {
            $f($ts, $j);
        }
    }

    private function _run2($ts, IReceiver $receiver) {
        for ($j = 1; $j <= 1_000_000; $j++) {
            $receiver->run($ts, $j);
        }
    }

    private function _run3($ts) {
        for ($j = 1; $j <= 1_000_000; $j++) {
            $this->_receiver->run($ts, $j);
        }
    }

    private function _run4($ts) {
        $receiver = $this->_receiver;
        for ($j = 1; $j <= 1_000_000; $j++) {
            $receiver->run($ts, $j);
        }
    }

    // ниже числа где 1 раз вызывается _runX
    // closure тяжело передается, а use +1 параметр добавляет +6 ms на один вызов, не на 1М вызовов
    $this->_run1($t, function($ts, $j) {}); // 38 ms - for 4 ms = 34 ms
    $this->_run1($t, function($ts, $j) use ($t) {}); // 44 ms - 4 = 40 ms
    $this->_run1($t, $fn); // 38 ms -4 = 34 ms
    $this->_run2($t, $receiver); // 31 - 4 = 27 ms << самый быстрый способ это передать receiver 1 раз, он станет локальным в методе
    $this->_run3($t); // 36 ms - 4 = 32 ms (дерганье объекта хуевое)
    $this->_run4($t); // 31 ms - 4 = 27 ms << тоже самый лучший варант

Другой тест: если 1М раз вызывать run, каждый раз передавая callback в виде function или receiver
    $this->_run(array($this, '_callback1')); // 280 ms
    $this->_run(function ($ts, $x) {}); // 214 ms, чуть быстрее
    $this->_run($receiver); // 125 ms объект с invoke
    $this->_run($receiver); // 111 ms без invoke, разница в 2.5 раз

Итого: closure как-то херово инлайнится внутрь, лучше от него избавляться.
А lamda-use вообще шляпа.
Правда вот современные либы типа Rachet/react все на этой блямбда-хуйне.

==============================================================

strings concatenations:

самые большие проблемы это автоприведение типов, на втором месте конкатенация.

$s = $int.$int.$int; // 139 ms // 4.54 ms jit
$s = "$int$int$int"; // 117 ms << лучше всего сразу в одну строку // 4.5 ms
$s = $int; $int .= $int; $s .= $int; // 143 ms, клеить заметно хуже // 4.5 ms

// если $a и $b string - то значения не имеет как склеивать
$s = $a.$b; // 27 ms
$s = "$a$b"; // 28 ms
$s = $a; $s .= $b; // 40 ms, клеить по очереди всегда пиздец

// но для длинных строк - все равно выгодно клеить в одну строку
$s = $a.$b.$a.$b.$a.$b.$a.$b.$a.$b.$a.$b; // 192..194 ms
$s = "$a$b$a$b$a$b$a$b$a$b$a$b"; // 139..140 ms << самый выгодный вариант
$s = "{$a}{$b}{$a}{$b}{$a}{$b}{$a}{$b}{$a}{$b}{$a}{$b}"; // 139..140 ms, нифига не меняется
$s = $a; $s .= $b, ... и так дофига раз // 700+ ms, пиздец вам всем, так делать не надо

Это все обясняется бесконечным memory alloc и перекладываем переменных из памяти в память в новую бОльшую ячейку.
При jit это все исправили.

==============================================================

Сравнение чисел, которые пришли из строк:

$old = '1753186451315114';
$new = '1753186451315114.001';

$x = ($new > $old); // 166 ms
$x = (strcmp($new, $old) == 1); // 19 ms

Сильно выгоднее сравнивать строками через strcmp.
Но важно чтобы количество знаков до плавающей точки было одинаковое, а само число было преставлено в правильном форматировании.

Важно: strcmp быстрее если это изначально string. Если это int, то все-таки быстрее $new > $old, php сам приведет к типам.

==============================================================

$s = implode(';', $array)
сильно быстрее чем
$s = $array[0].';'.$array[1].';'....;
Особенно если индексы строковые.
Разница в N раз, где N это количество элементов в массиве.
implode (он же formerly join) экономит операции конкатенации и экономит поиск ключей в массиве.

Если массив очень большой и надо какие-то ключи пропускать - то лучше всего foreach ($key => $value) и внутри клеить строку.
Хотя тоже хуйово, но это все-таки быстрее чем прямая склейка.

==============================================================

memory allocations

Если переменная нужна 1 раз - то ее лучше не аллоцировать.
$a = explode(';', getData());
будет в 2 раза быстрее чем
$a = getData(); $a = explode(';', $data);

Хотя конечно читабельность кода теряется, но php не умеет такое инлайнить.

==============================================================

typing

Типизация конкатенацией - лажа, лучше явно string перед ним.
$j.''; // 24.5 ms (это без jit)
(string) $j; // 19.5 (это без jit)
strval($j); // 19.5

==============================================================

cast int to string with concatenations

// 14 ms - if $a $b strings
$x = $a.$b;

// 96 ms - if $a $b ints
$x = $a.$b;

// 155 ms - if $a $b strings
$x = sprintf('%d%d', $a, $b);

// 77 ms - if $a $b ints
$x = sprintf('%d%d', $a, $b); << если у вас N int чисел, которые надо склеить как строку - сильно выгоднее sprintf

// 32 ms - cast int to string
$x = (string) $a;

==============================================================

поиск подстроки в строке:

if (substr_count($s1, $s2)) { $x++; } // 14.28 ms // 9.35 jit
if (str_contains($s1, $s2)) { $x++; } // 12.38 ms // 9.15 ms jit << без jit самое быстрое
if (strpos($s1, $s2) !== false) { $x++; } // 14.68 ms // 8.47 jit << с jit лучше испорльзовать strpos

==============================================================

ifы:
и это йибать странно, у меня нет объяснений

// быстрее прыгнуть в if чем за него, это заставляет писать if (true) {} else { logic here } если нужно false
if (true) {} // 1.28 ms
if (false) {} // 2.84 ms

// для int проблем нет, хотя они и медленее :)
if (1) {} // 4.45 ms
if (0) {} // 4.73 ms

Upd: Неожиданное поведение связано с предсказанием переходов процессора и внутренней реализацией PHP: пустой true быстрее пустого false.
Если много пустых условий (встречается редко), убедись, что горячие пути чаще истинны (branch prediction friendly).

==============================================================

IF vs MIN/MAX

Если кажется что выгоднее делать конструкцию типа $a = min($a, $b) - то нихуя.
// loop 3.16 ms
for ($j = 0; $j < 1_000_000; $j++) {
    $b = rand(); // rand 11.84 ms (loop + rand = 15 ms)
    //$a = max($a, $b); // 32-15 = 17 ms
    if ($b > $a) { // 2 ms, if сильно быстрее
        $a = $b;
    }
}

==============================================================

Вложенные IF и AND

$a = 1;
$b = 2;

if ($a > 0) {
    if ($b > 0} {
        ...
    }
}

быстрее чем if ($a > 0 && $b > 0) { ... }

if ($a > 0 && $b > 0) {} // 4.38 ms на 1М вызовов
if ($a > 0) { // 1.65 ms на 1М вызовов
    if ($b > 0) {
        // ...
    }
}

Сука блять, какого хера?
Upd: это как индексы в SQL, надо наперед выносить первый. Но если написать все сразу - то будет проверять все, потом еще и в AND лепить.

==============================================================

IF OR

OR таки работает как short-circuit, но все равно с какой-то хуйней:
if ($j > 0 || $j > 1 || $j > 2 || $j > 3 || $j > 4) {}
и чем больше я ставлю условий - тем медленее срабатыват этот йобанный if, хотя short-circuit реально срабатывает только на 1м условии:
я пробовал заменить $j на функцию с принтом, чтобы понять какая вызовется.

// 13 ms -- и продолжает расти если увеличиваю количество условий
// хотя реально проверяется только первое истинное условие (short circuit)
if ($j > 0 || $j > 1 || $j > 2 || $j > 3 || $j > 4) {}

// 5 ms -- такая конструкция сильно быстрее и задержка не растет с количеством if-ов, хоть 100 штук поставь
if ($j > 0) {
} elseif ($j > 1) {
} elseif ($j > 2) {
} elseif ($j > 3) {
} elseif ($j > 4) {
}

Но, тут очень важный момент: переходить с OR на elseif выгоднее если чаще всего все условия true.
Хотя на большом количестве параметров if-elseif все равно быстрее.
Я пробовал даже писать if (1 || ...300_бессмысленных_условий) - начинается мрак на 700 ms

В примерах ниже $j и $t больше нуля всегда и меняются динамически:

// 8.44 ms
if ($j < 0 || $t < 0) {}

// 8.44 ms - тут будет проверка всех условий, поэтому скорости не добавляет для двух операций
if ($j < 0) {
} elseif ($t < 0) {
}

// 6.7 ms
if ($j > 0 || $t > 0) {}

// 5.6 ms - тут сработает только первый if
if ($j > 0) {
} elseif ($t > 0) {
}

// 16.5 ms
if ($j < 0 || $t < 0 || $amount < 0 || $price < 0) {}

// 13.6 ms << все равно быстрее если параметров больше, и дело не в типизации, типы одинаковые
if ($j < 0) {
} elseif ($t < 0) {
} elseif ($amount < 0) {
} elseif ($price < 0) {
}

// 11 ms
if ($j > 0 || $t > 0 || $price > 0 || $amount > 0) {}

// 5.6 ms << еще быстрее
if ($j > 0) {
} elseif ($t > 0) {
} elseif ($amount > 0) {
} elseif ($price > 0) {
}

// 7.8 ms
$x = ($a || $b);

// 7.75 ms, но $x заранее инициирован в false
if ($b) {
    $x = true;
} elseif ($b) {
    $x = true;
}

Итого: чем больше параметров - тем выгоднее переходить на if elseif.
Так и до goto label недалеко докатиться.

==============================================================

$x = ($j > 100); // 6.23 ms

if ($j > 100) { // 5.8 ms, потому что экономится одно присвоение false
    $x = true;
}

==============================================================

Не выебуйся с присвоениями:

$changeAsk = $changeBid = true; // 7.7 ms

$changeAsk = true; $changeBid = true; // 7.4 ms

==============================================================

if vs switch:

так как скорость у switch & if-else одинаковая при jit, скорее всего jit умеет превращать if-else в switch.
Но, он явно не умеет косить пустые и бессмысленные if-else и пустые switch.

// 10 ms
// 0.5 ms jit
if ($opcode === 0x8) {

} elseif ($opcode === 0xA) {

} elseif ($opcode === 0x9) {

} else {

}

// 6.3 ms
// 0.5 ms jit
switch ($opcode) {
    case 0x8:
        break;
    case 0xA:
        break;
    case 0x9:
        break;
    default:
        break;
}

// супер важно чтобы тип данных в $x и case совпадал.
// если совпадает - 17 ms, если не совпадает - 60 ms (это все без jit).
// лучше всего сделать switch ((int)$x) - так будет 45 ms. Иначе оно походу типизирует под каждый case. Нахуя, не понятно.
// см string typing
switch ($x) {
    case 1:
        break/return; // а вот разницы return или break - значения никакого.
    case 2:
        break/return;
}

==============================================================

switch ($a.'-'.$b) { ...

$key = $a.'-'.$b;
switch ($key) { ... // быстрее в 3 раза тоже, видимо оно как-то неэффективно каждый раз сравнивает, пиздец блять

==============================================================

// 25 ms
if ($j > rand(0, 100)) {
    $rejected = true;
} else {
    $rejected = false;
}

// 24 ms
$rejected = ($j > rand(0, 100));

==============================================================

consts:

if (defined('myconst')) {} // 3.9 ms если false, 1.27 ms если true. Что тоже пиздец как логично ж
if ($this->_boolVar) {} // 4.88 ms

==============================================================

switch ($string)
    case CONST_STRING: ...
vs
switch ($int)
    case CONST_INT: ...

string const = 15-17 ms на 1М вызовов
int const = 8-10 ms на 1М вызовов
int const лучше в 2 раза


==============================================================

fill массивов:

for ($j = 0; $j < 1_000_000; ++$j) {
    $this->_test();
}

// 1098 ms
// 110 ms << при jit  это самый быстрый способ, без jit - самый медленный
private function _test() {
    $x = rand(1, 100);
    $a = [];
    for ($i = 1; $i <= $x; $i++) {
        $a[$i] = $i;
    }
}

// 930 ms - без индекса быстрее на 10%
// 499 ms << лучше с индексом при jit
private function _test() {
    $x = rand(1, 100);
    $a = [];
    for ($i = 1; $i <= $x; $i++) {
        $a[] = $i;
    }
}

// 1010 ms, если массив уже заполнен и я его копирую - трохи быстрее
// 490 ms
private $_bucket = array_fill(0, 100, 0);
private function _test() {
    $x = rand(1, 100);
    $a = $this->_bucket;
    for ($i = 1; $i <= $x; $i++) {
        $a[$i] = $i;
    }
}

// 865 ms, тоже самое, только bucket по указателю
// это странно конечно, работает только с массивами, с обычными переменными делает сильно хуже
// надо быть аккуратным, по перетирарается сам $this->_bucket
private $_bucket = array_fill(0, 100, 0);
private function _test() {
    $x = rand(1, 100);
    $a = &$this->_bucket;
    for ($i = 1; $i <= $x; $i++) {
        $a[$i] = $i;
    }
}

// 1180 ms, то то есть вызов $this->xxx пиздец тяжелый
// 406 ms
// но если надо таки записать в свойство, то лучше так чем собирать массив у себя локально потом присваивать - 506 ms jit
private $_bucket = array_fill(0, 100, 0);
private function _test() {
    $x = rand(1, 100);
    for ($i = 1; $i <= $x; $i++) {
        $this->_bucket[$i] = $i;
    }
}

==============================================================

Наиболее эффективный способ оценки пустого массива:

$socket = socket_create(AF_INET, SOCK_DGRAM, SOL_UDP);
$a = [$socket];

if (!empty($a)) {$x++;} // 6.1 ms / 3.21 ms jit << быстрый если массива нет (переменная не инициирована)
if ($a) {$x++;} // 4.38 ms / 2.18 ms jit << это самый быстрый способ
if (count($a) > 0) {$x++;} // 7.4 ms / 2.21 ms jit

==============================================================

echo vs print

извечный срач.
echo быстрее на 1.1% чем print, потому что print еще делает return 1,
и на уровне zendvm echo - это одна opcode команда, а print - две.

==============================================================

sprintf vs number_format
sprintf быстрее примено на 20% и требует меньше памяти
Тест на 1M вызовов, без jit и без opcache
number_format(123456.123456789123, 12, '.', ''); // 375 ms
sprintf('%.12f', 123456.123456789123); // 326 ms

==============================================================

ini_set('zend.enable_gc', 0);

Убирает запуск garbage collector, все становится чуть сложнее, но циклы стабильне.

==============================================================

time() быстрее чем microtime(true)
Скорее всего это связано с int/float, сравнение int работает быстрее, да и сам time выдает результат быстрее

if (microtime(true) > $this->_workTimeLimit) {} // 46-48 ms
if (time() > $this->_workTimeLimit) {} // 38 ms

==============================================================

1M вызовов:
microtime(true); // 41.7 ms
hrtime(true); // 41.7 ms

При этом hrtime точнее, но он отличается от сервера к серверу.
Удобнее получать в начале microtime+hrtime, а потом по hrtime мерять разницу.

==============================================================

unpack при разных типах данных требует указывать имена ключей в массиве.
При этом чем короче ключи - тем быстрее разбор.

// 166 ms
unpack("Ca/eb/Vc/ed/Ve/Vf/eg/eh/ei/el/em/en", $message);

// 312 ms
unpack("atype/dts_push/Npair_id/dts_event/Nsequence/Nsuffix/dask/dask_size/dask_breakout/dbid/dbid_size/dbid_breakout", $message);

==============================================================

Сравнение производительности hash-функций
Тестировалось вызовом hash('murmur3a', microtime(true)+rand())
Результаты на 100_000 вызовов в секундах

crc32 = 32 = 0.030
md2 = 128 = 0.46
md4 = 128 = 0.051
md5 = 128 = 0.055 (0.05 если вызывать md5())
fnv164 = 64 = 0.04
fnv1a64 = 64 = 0.038
xxh3 = 64 = 0.039
xxh64 = 64 = 0.045
xxh128 = 128 = 0.045
haval128,3 = 0.10
haval128,4 = 0.12
haval128,5 = 0.14
sha1 = 160 = 0.057 (0.052 если вызывать sha1)
ripemd128 = 128 = 0.07
tiger128,3 = 128 = 0.054
snefru = 128 = 0.30
gost = 256 = 0.24
murmur3f = 128 = 0.042
murmur3a = 32 = 0.038
murmur3c = 64 = 0.043

== выводы ==
Если аналог md5 (128 bit) - то murmur3f
Если можно более коротких хеш (64 bit) - то fnv1a64
Если не важны коллизии - то crc32

==============================================================

Рандомное число (тест на 1М вызовов):

rand(1, 9999999); // 22 ms
rand(1, PHP_INT_MAX); // 24 ms
uniqid(); // 1000 ms << самое медленное
rand(); // 12 ms << самое быстрое
hash('murmur3a', microtime(true)+rand()); // 230 ms

==============================================================

Количество потоков

Конечно это не всегда изи сделать, но если у вас есть 10 скриптов, которые суммарно зажирают 50% от 1 vcpu,
то лучше слепить это в один скрипт, и он станет жрать примерно 40% от 1 vcpu.
Это объясняется context-switching-ом: чем меньше переключений процессов, тем больше непрерывного времени у вашего процесса,
и тем выше вероятность попасть в NUMA-aw + branch-prediction: это когда ваши данные затянутся в L-кеш проца.
Такого можно добиться просто за счет того, что процесс один.

Второй важный момент: надо стараться писать код так, чтобы инструкций в процессор было как можно меньше.
Можно поймать магию: например, ваш код это 200 инструкций cpu. Переключение контекста - 50 инструкций. Окно контекста 100. (цифры для примера, зависят от операционки, гипервизора и еще кучи всего)
То ваш процесс (который на 200 инструкций) на самом деле выполняется: 100 (ваших) + 50 на переключение контекста + 100 на другой процесс + 50 на переключение + 100 на ваш процесс.
Итого 200 превращаются в 400 минимум.
А если ужаться до окна (100) - то будет 100, без потерь.

==============================================================

OPCACHE + JIT

NB! шо opcache+jit это жопа с eval, если есть eval smarty - всему пизда сразу же

Синтетический тест на вызовы методов и доступ к свойствам:
php -f 1.php // 791 ms
php -d opcache.enable=1 -d opcache.validate_timestamps=1 -d opcache.revalidate_freq=0 -d opcache.enable_cli=1 -f 1.php // 642 ms opcache only
php -d opcache.enable=1 -d opcache.validate_timestamps=1 -d opcache.revalidate_freq=0 -d opcache.enable_cli=1 -d opcache.jit_buffer_size=100M -d opcache.jit=function -f 1.php // 244 ms
php -d opcache.enable=1 -d opcache.validate_timestamps=1 -d opcache.revalidate_freq=0 -d opcache.enable_cli=1 -d opcache.jit_buffer_size=100M -d opcache.jit=tracing -f 1.php // 114 ms

aws gn vs g сетевухи
Если не использовать DPDK/Kernel-by-pass то нет никакой разницы между gn или g для реального подключения по ws/udp.
Но вот скорость обработки самого сетевого стека сильно зависит от cpu и тут c8g выигрывает с ебейшим отрывом у всего остального.
Тестировал на подключении к fstream к одному IP из кластера c7gn, c7g, c8g.

m5zn.xlarge (intel xeon 4.5Ghz tokyo-only)
php 472 ms
php +opcache 333 ms
php +opcache +jit 78ms
network
no-jit  0.017221922	0.016291	0.010026	0.039792
jit	    0.016803216	0.015686	0.009896	0.03596

c7a.xlarge (top of amd 3.7Ghz)
php 491 ms
php +opcache 402 ms
php +opcache +jit 59 ms << супер быстрая математика
network
no-jit  0.023317672327672	0.02271	0.00912	0.0398
jit     не тестил, потому что проигрывает

c8g.xlarge << top of all
php 608 ms
php +opcache 384 ms
php +opcache +jit 75-80 ms << математика быстрая, но сеть просто ебическая
network << самый быстрый, IGW тоже топ
no-jit 0.0088250438247012	0.0080535	0.005574	0.033326 << монстр по сети, в 2.5 раза быстрее c6gn, в 1.5 раза быстрее c7g*
jit    0.008585994011976	0.007398	0.005503	0.032228 << не особо меняет

c8g.metal-24xl (arm, 96 vcpu)
php 607 ms
php +opcache 384 ms
php +opcache +jit 76 ms (чуть быстрее из-за отсутсвия context switching)
network
no-jit  0.005952433	0.005753	0.004636	0.014024 << top of network and performance, еще в 1.5 быстрее чем c8g shared, количество ядер решают на сетевой стек
jit     0.005866824	0.005636	0.004512	0.015603

c7gn.xlarge, c7g.xlarge (arm, 2.6Ghz, L-1M)
php 655 ms
php +opcache 435 ms, stable
php +opcache +jit 88 ms
network c7gn.xlarge
no-jit 	0.011871339	0.010371	0.007511	0.037104
jit 	0.012685706	0.0107155	0.007691	0.269821 делает чуть хуже?
network c7g.xlarge
no-jit  0.011913541	0.0101565	0.007481	0.036936 не похоже что чем-то отличется от c7gn
jit     0.012632865	0.0106905	0.007413	0.285803 делает чуть хуже, но нет разницы с c7gn

c7gn.metal (arm,  64 vcpu, 2.6Ghz, L-1M) - bare metal, без context-switching'a
php 655 ms
php +opcache 435 ms
php +opcache +jit 88 ms << больше ядер никак не помогает php-процессу и это логично
network
no-jit 	0.008225013986014	0.007976	0.006318	0.020987 << а вот не bare-metal у меня нет context-switching и больше ядер, сеть стала быстрее на +37%
jit     0.0079046816367265	0.0077845	0.006264	0.020894

c6gn.xlarge (arm, 2.5 GHz)
php 789 ms
php +opcache 641 ms
php +opcache +jit 114 ms
php +compiled 8.2.28 - 790 ms (= сборка php -O3 native не помогает)
php +compiled +opcache - 638 ms
php +compiled +opcache + jit 114 ms
network 0.0227 ms/udp loopback << это нитро сетевуха ENA, без ENA express
no-jit  0.02284175386 avg	0.02055975 med	0.01138 min 	0.4851 max
jit     0.02276954401 avg	0.020537 med	0.011126 min	0.37818 max не стабильное, но медиана самая низкая

c6a.xlarge (amd, 2.65 Ghz)
php 528 ms
php +opcache 380..574 ms, странно делает хуже и прыгает
php +opcache +jit 65 ms, стабильно << best of
network 0.045 ms/udp loopback, сеть вдвое хуже чем arm/intel
no-jit	0.048085801198801 avg	0.051471 med	0.01847 min	0.183734 max
jit 	0.045852571428571 avg	0.046251 med	0.02055 min	0.095102 max

c6i.xlarge (intel, 3.5 Ghz, сильно больше L-кешей)
php 520 ms
php +opcache 396 ms
php +opcache +jit 90 ms
network 0.0233 ms/udp loopback
no-jit  0.025813836 avg	0.0254155 med	0.011826 min	0.052407 max
jit     0.023273431 avg	0.022677 med	0.010959 min	0.054387 max    самое стабильное, но на 2% хуже arm

a1.metal (old arm)
php 2090 ms
php +opcache +jit 183 ms (ускоренеи норм, но все равно лажа с c6*)
сеть 0.03 ms/udp loopback, хуже в 1.5 раза
